{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feafe47d-8d2e-4182-9444-3bb89cd7ca3c",
   "metadata": {},
   "source": [
    "<h1>Pre-processing and Labelling of Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "199f08e5-a458-4295-8b70-3450513a42cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (11364, 150, 150)\n",
      "y_train shape: (11364, 3)\n",
      "X_test shape: (3789, 150, 150)\n",
      "y_test shape: (3789, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the image directory and image size\n",
    "image_dir = 'D:\\Conv-Capsnet\\Dataset'\n",
    "image_size = (150, 150)\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_data(image_dir, image_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "    classes = ['covid', 'pneumonia', 'normal']\n",
    "    \n",
    "    for class_label, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(image_dir, class_name)\n",
    "        for img_filename in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_filename)\n",
    "            try:\n",
    "                # print(\"Loading image:\", img_path)  # Print the image path for debugging\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Read image as grayscale\n",
    "                \n",
    "                if img is None:\n",
    "                    print(f\"Error loading image: {img_path}\")\n",
    "                    continue\n",
    "\n",
    "                img = cv2.resize(img, image_size)  # Resize image to 150x150\n",
    "                img = img.astype('float32') / 255.0  # Normalize pixel values to [0, 1]\n",
    "                data.append(img)\n",
    "                labels.append(class_label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image: {img_path} - {str(e)}\")\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Convert labels to one-hot encoded vectors\n",
    "    labels = to_categorical(labels, num_classes=len(classes))\n",
    "    \n",
    "    return data, labels\n",
    "    \n",
    "# Load and preprocess the data\n",
    "data, labels = load_and_preprocess_data(image_dir, image_size)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# Print the shape of the training and testing data\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ad11d1-70c0-45a6-bf4d-49c97da0d224",
   "metadata": {},
   "source": [
    "<h1> Implmentation of the propsed model - ConvCapsnet </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebcc1978-836e-45f8-a11e-25ae1b4534fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4490163-3cbb-4373-b543-76cead2c3d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for input image\n",
    "X = tf.keras.layers.Input(shape=(150, 150, 1), name=\"X\", dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a977a75a-062b-444e-9696-61af235ada8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the convolutional parameters\n",
    "conv1_parameters = {\n",
    "    \"filters\": 16,\n",
    "    \"kernel_size\": (5, 5),\n",
    "    \"strides\": (1, 1),\n",
    "    \"padding\": \"same\",\n",
    "    \"activation\": tf.nn.relu\n",
    "}\n",
    "conv2_parameters = {\n",
    "    \"filters\": 32,\n",
    "    \"kernel_size\": (5, 5),\n",
    "    \"strides\": (2, 2),\n",
    "    \"padding\": \"same\",\n",
    "    \"activation\": tf.nn.relu\n",
    "}\n",
    "\n",
    "conv3_parameters = {\n",
    "    \"filters\": 64,\n",
    "    \"kernel_size\": (5, 5),\n",
    "    \"strides\": (1, 1),\n",
    "    \"padding\": \"same\",\n",
    "    \"activation\": tf.nn.relu\n",
    "}\n",
    "\n",
    "conv4_parameters = {\n",
    "    \"filters\": 128,\n",
    "    \"kernel_size\": (9, 9),\n",
    "    \"strides\": (1, 1),\n",
    "    \"padding\": \"same\",\n",
    "    \"activation\": tf.nn.relu\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "023c6232-3923-4dc6-a7c7-8ccc41c1046a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create the four convolutional layers\n",
    "\n",
    "conv1 = layers.Conv2D(name=\"conv1\", **conv1_parameters)(X)\n",
    "conv2 = layers.Conv2D(name=\"conv2\", **conv2_parameters)(conv1)\n",
    "conv3 = layers.Conv2D(name=\"conv3\", **conv3_parameters)(conv2)\n",
    "conv4 = layers.Conv2D(name=\"conv4\", **conv4_parameters)(conv3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6cced6b-02d5-4b27-9621-95f928e756af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(s, ax=-1, epsilon=1e-7, name=None): \n",
    "    with tf.name_scope(name):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=ax, keepdims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "        return squash_factor * unit_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4016da24-188a-4166-ace1-0950df37e939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary capsule layer \n",
    "\n",
    "primary_capsule_input = tf.reshape(conv4, [-1, 1152 , 8], name=\"primary_capsule_input\")\n",
    "primary_capsule_output = squash(primary_capsule_input, name=\"primary_capsule_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "954d783b-abbb-4578-941f-2669127e492d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.tile), but are not present in its tracked objects:   <tf.Variable 'W:0' shape=(1, 1152, 3, 16, 8) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    }
   ],
   "source": [
    "# Secondary Capsule layer \n",
    "\n",
    "# Initializing weight matrix \n",
    "\n",
    "W_init = tf.random.normal(shape=(1, 1152, 3, 16, 8), stddev=0.01, name=\"W_init\", dtype=tf.float32)\n",
    "W = tf.Variable(W_init, name=\"W\")\n",
    "\n",
    "# Tile the weight matrix \n",
    "\n",
    "W_tiled = tf.tile(W, [tf.shape(X)[0], 1, 1, 1, 1], name=\"W_tiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "155aa679-cd11-404c-becd-71ebc366f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand output of primary capsule (batchsize x 1152 x 8) to (batchsize x 1152 x 3 x 8 x 1) \n",
    "\n",
    "primary_capsule_output_expanded = tf.expand_dims(primary_capsule_output, -1, name=\"primar_capsule_output_expanded\")\n",
    "primary_capsule_output_tile = tf.expand_dims(primary_capsule_output_expanded, 2, name=\"primary_capsule_output_tile\")\n",
    "primary_capsule_output_tiled = tf.tile(primary_capsule_output_tile, [1, 1, 3, 1, 1], name=\"primary_capsule_output_tiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da42082e-b579-4523-bd9c-7ab5c8c64910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secondary Capsule Prediction Vector uj|i = Wij * uij for all i, j \n",
    "\n",
    "secondary_capsule_predicted = tf.matmul(W_tiled, primary_capsule_output_tiled, name=\"secondary_capsule_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a26c9724-8435-46fa-9331-befae338e4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1152, 3, 16, 1) dtype=float32 (created by layer 'tf.linalg.matmul')>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondary_capsule_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f8ee4c9-527e-4cdf-adb0-c689d5561e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic Routing \n",
    "\n",
    "# Initialize bias bij to zero \n",
    "\n",
    "raw_weights_round1 = tf.zeros([tf.shape(X)[0], 1152, 3, 1, 1], dtype=tf.float32, name=\"raw_weights_round1\")\n",
    "\n",
    "# Round 1 \n",
    "\n",
    "# Coupling Coeffecient Cij = softmax(bij) \n",
    "\n",
    "routing_weights_round1 = tf.nn.softmax(raw_weights_round1, axis=2, name=\"routing_weights_round1\")\n",
    "\n",
    "# Weighted Sum Sij = Summation(Cij * uj|i)\n",
    "\n",
    "weighted_predictions_round1 = tf.multiply(routing_weights_round1, secondary_capsule_predicted, name=\"weighted_predictions_round1\")\n",
    "weighted_sum_round1 = tf.reduce_sum(weighted_predictions_round1, axis=1, keepdims=True, name=\"weighted_sum_round1\")\n",
    "\n",
    "# vj = SQUASH(Sj) \n",
    "\n",
    "secondary_capsule_output_round1 = squash(weighted_sum_round1, ax=-2, name=\"secondary_capsule_output_round1\")\n",
    "\n",
    "secondary_capsule_output_round1 \n",
    "\n",
    "# Update bias bij = bij + uj|i . vj\n",
    "\n",
    "secondary_capsule_output_round1_tiled = tf.tile(secondary_capsule_output_round1, [1, 1152, 1, 1, 1], name=\"secondary_capsule_output_round1_tiled\")\n",
    "\n",
    "agreement_after_round1 = tf.matmul(secondary_capsule_predicted, secondary_capsule_output_round1_tiled, transpose_a=True, name=\"agreement_after_round1\")\n",
    "\n",
    "raw_weights_round2 = tf.add(raw_weights_round1, agreement_after_round1, name=\"raw_weights_round2\")\n",
    "\n",
    "# Round 2 \n",
    "\n",
    "# Coupling Coeffecient Cij = softmax(bij) \n",
    "\n",
    "routing_weights_round2 = tf.nn.softmax(raw_weights_round2, axis=2, name=\"routing_weights_round2\")\n",
    "\n",
    "# Weighted Sum Sij = Summation(Cij * uj|i)\n",
    "\n",
    "weighted_predictions_round2 = tf.multiply(routing_weights_round2, secondary_capsule_predicted, name=\"weighted_predictions_round2\")\n",
    "weighted_sum_round2 = tf.reduce_sum(weighted_predictions_round2, axis=1, keepdims=True, name=\"weighted_sum_round2\")\n",
    "\n",
    "# vj = SQUASH(Sj) \n",
    "\n",
    "secondary_capsule_output_round2 = squash(weighted_sum_round2, ax=-2, name=\"secondary_capsule_output_round2\")\n",
    "\n",
    "# Update bias bij = bij + uj|i . vj\n",
    "\n",
    "secondary_capsule_output_round2_tiled = tf.tile(secondary_capsule_output_round2, [1, 1152, 1, 1, 1], name=\"secondary_capsule_output_round2_tiled\")\n",
    "\n",
    "agreement_after_round2 = tf.matmul(secondary_capsule_predicted, secondary_capsule_output_round2_tiled, transpose_a=True, name=\"agreement_after_round2\")\n",
    "raw_weights_round3 = tf.add(raw_weights_round2, agreement_after_round2, name=\"raw_weights_round3\")\n",
    "\n",
    "# Round 3 \n",
    "\n",
    "# Coupling Coeffecient Cij = softmax(bij) \n",
    "\n",
    "routing_weights_round3 = tf.nn.softmax(raw_weights_round3, axis=2, name=\"routing_weights_round3\")\n",
    "\n",
    "# Weighted Sum Sij = Summation(Cij * uj|i)\n",
    "\n",
    "weighted_predictions_round3 = tf.multiply(routing_weights_round3, secondary_capsule_predicted, name=\"weighted_predictions_round3\")\n",
    "weighted_sum_round3 = tf.reduce_sum(weighted_predictions_round3, axis=1, keepdims=True, name=\"weighted_sum_round3\")\n",
    "\n",
    "# vj = SQAUSH(sj)\n",
    "\n",
    "secondary_capsule_output_round3 = squash(weighted_sum_round3, ax=-2, name=\"secondary_capsule_output_round3\")\n",
    "\n",
    "# Update bias bij = bij + uj|i . vj (OPTIONAL SINCE THIS IS THE LAST ROUND)\n",
    "\n",
    "seecondary_capsule_output_round3_tiled = tf.tile(secondary_capsule_output_round2, [1, 1152, 1, 1, 1], name=\"secondary_capsule_output_round2_tiled\")\n",
    "\n",
    "agreement_after_round3 = tf.matmul(secondary_capsule_predicted, seecondary_capsule_output_round3_tiled, transpose_a=True, name=\"agreement_after_round3\")\n",
    "\n",
    "raw_weights_round4 = tf.add(raw_weights_round3, agreement_after_round3, name=\"raw_weights_round4\")\n",
    "\n",
    "# End of Dynamic Routing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02f5a949-49ec-4dd9-ac8c-9ea642f60854",
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_capsule_output = secondary_capsule_output_round3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e2bf5d8-a6b6-48b4-bbc9-41ee4d12281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated Class Probabilities \n",
    "\n",
    "def safe_norm(s, ax=-1, epsilon=1e-7, keepdims_v=False, name=None):\n",
    "    with tf.name_scope(name):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=ax,\n",
    "                                     keepdims=keepdims_v)\n",
    "        return tf.sqrt(squared_norm + epsilon)\n",
    "\n",
    "y_prob = safe_norm(secondary_capsule_output, ax=-2, name=\"y_prob\")\n",
    "y_prob_argmax = tf.argmax(y_prob, axis=2, name=\"y_prob_argmax\") \n",
    "\n",
    "y_predicted = tf.squeeze(y_prob_argmax, axis=[1, 2], name=\"y_predicted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f721c0ae-f227-426d-9de5-b324faa5f5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
